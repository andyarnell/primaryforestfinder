{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5839fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "import math\n",
    "import glob\n",
    "\n",
    "def split_geopackage_to_csv(\n",
    "    input_gpkg, \n",
    "    output_folder, \n",
    "    chunk_size=10000, \n",
    "    prefix=\"chunk\", \n",
    "    columns=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits a GeoPackage into multiple CSV files with WKT geometries.\n",
    "    Skips chunks that already exist based on filename pattern.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_gpkg : str\n",
    "        Path to the input GeoPackage file\n",
    "    output_folder : str\n",
    "        Folder to save the output CSV files\n",
    "    chunk_size : int\n",
    "        Number of rows per chunk\n",
    "    prefix : str\n",
    "        Prefix for output CSV files\n",
    "    columns : list\n",
    "        List of columns to include in output. If None, includes all columns\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Read the GeoPackage\n",
    "        print(f\"Reading GeoPackage: {input_gpkg}\")\n",
    "        gdf = gpd.read_file(input_gpkg)\n",
    "        \n",
    "        # Get total number of rows\n",
    "        total_rows = len(gdf)\n",
    "        print(f\"Total features: {total_rows}\")\n",
    "        \n",
    "        # Calculate number of chunks\n",
    "        num_chunks = math.ceil(total_rows / chunk_size)\n",
    "        print(f\"Splitting into {num_chunks} chunks of {chunk_size} rows each\")\n",
    "        \n",
    "        # If columns specified, ensure 'geometry' is included\n",
    "        if columns is not None and 'geometry' not in columns:\n",
    "            columns.append('geometry')\n",
    "            \n",
    "        # Process each chunk\n",
    "        for i in range(num_chunks):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = min((i + 1) * chunk_size, total_rows)\n",
    "            \n",
    "            # Create output filename with row information\n",
    "            output_file = os.path.join(output_folder, f\"{prefix}_{start_idx}_to_{end_idx}_of_{total_rows}.csv\")\n",
    "            \n",
    "            # Check if file already exists\n",
    "            if os.path.exists(output_file):\n",
    "                print(f\"Chunk {i+1}/{num_chunks} (rows {start_idx} to {end_idx}) already exists - skipping\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing chunk {i+1}/{num_chunks} (rows {start_idx} to {end_idx})\")\n",
    "            \n",
    "            # Extract chunk\n",
    "            chunk = gdf.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # Filter columns if specified\n",
    "            if columns is not None:\n",
    "                chunk = chunk[columns]\n",
    "                \n",
    "            # Convert to DataFrame with WKT geometry\n",
    "            df = pd.DataFrame(chunk)\n",
    "            df['geometry'] = df['geometry'].apply(lambda x: x.wkt if x else \"\")\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved to {output_file}\")\n",
    "            \n",
    "        print(f\"Processing complete! {num_chunks} CSV files created in {output_folder}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_gpkg}: {str(e)}\")\n",
    "        \n",
    "\n",
    "def process_all_geopackages_in_folder(\n",
    "    input_folder,\n",
    "    output_folder,\n",
    "    pattern=\"*_highways.gpkg\",\n",
    "    chunk_size=10000,\n",
    "    columns=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Process all geopackage files in a folder that match a pattern\n",
    "    \"\"\"\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Find all matching files\n",
    "    search_pattern = os.path.join(input_folder, pattern)\n",
    "    geopackage_files = glob.glob(search_pattern)\n",
    "    \n",
    "    if not geopackage_files:\n",
    "        print(f\"No files matching '{pattern}' found in {input_folder}\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {len(geopackage_files)} files to process\")\n",
    "    \n",
    "    # Process each file\n",
    "    for i, gpkg_file in enumerate(geopackage_files):\n",
    "        filename = os.path.basename(gpkg_file)\n",
    "        # Extract prefix (remove _highways.gpkg)\n",
    "        prefix = filename.replace(\"_highways.gpkg\", \"\")\n",
    "        \n",
    "        print(f\"\\nProcessing file {i+1}/{len(geopackage_files)}: {filename}\")\n",
    "        print(f\"Using prefix: {prefix}\")\n",
    "        \n",
    "        # Process this file\n",
    "        split_geopackage_to_csv(\n",
    "            input_gpkg=gpkg_file,\n",
    "            output_folder=output_folder,\n",
    "            chunk_size=chunk_size,\n",
    "            prefix=prefix,\n",
    "            columns=columns\n",
    "        )\n",
    "        \n",
    "    print(f\"\\nAll files processed! Check results in {output_folder}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba6a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_folder = r\"C:\\Users\\Arnell\\OneDrive - Food and Agriculture Organization\\project_work\\p0002_primary_forest_support\\work_in_progress\\roads\\osm\\osm_regional_250521\"\n",
    "# input_gpkg_name = \"africa_highways.gpkg\"\n",
    "# input_gpkg_path = os.path.join(in_folder, input_gpkg_name)\n",
    "# print (f\"Input GeoPackage path: {input_gpkg_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc312ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 files to process\n",
      "\n",
      "Processing file 1/7: africa_highways.gpkg\n",
      "Using prefix: africa\n",
      "Reading GeoPackage: C:\\Users\\Arnell\\OneDrive - Food and Agriculture Organization\\project_work\\p0002_primary_forest_support\\work_in_progress\\roads\\osm\\osm_regional_250521\\africa_highways.gpkg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your input folder with geopackages\n",
    "    in_folder = r\"C:\\Users\\Arnell\\OneDrive - Food and Agriculture Organization\\project_work\\p0002_primary_forest_support\\work_in_progress\\roads\\osm\\osm_regional_250521\"\n",
    "    \n",
    "    # Where to save the CSV files\n",
    "    output_folder = os.path.join(in_folder, \"geo_csvs\")\n",
    "    \n",
    "    # Process all files\n",
    "    process_all_geopackages_in_folder(\n",
    "        input_folder=in_folder,\n",
    "        output_folder=output_folder,\n",
    "        pattern=\"*_highways.gpkg\",\n",
    "        chunk_size=10000000,\n",
    "        # columns=['osm_id', 'highway', 'geometry']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79b136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
